{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc05a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_absolute_percentage_error,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import geopandas as gpd\n",
    "from geopy.distance import distance,geodesic\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f0d82e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# please download data at https://www.dropbox.com/s/uquijy335rg0kjn/date-hour-soo-dest-2022.csv.gz?dl=0\n",
    "data = pd.read_csv('date-hour-soo-dest-2022.csv.gz',compression='gzip',header=None)\n",
    "data.columns = ['Date', 'Hour', 'Origin', 'Destination', 'Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c53f8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Date'].apply(lambda x: x.split('-')[1])\n",
    "data = data.loc[data['Month'].isin(['09','10'])]\n",
    "data['OD'] = data['Origin'] + ' - ' + data['Destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d59ca589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.pivot_table(data,index=['Date','Hour'],columns=['OD'],fill_value=0).reset_index()\n",
    "data.columns = [i[1] if i[0]=='Number' else i[0] for i in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d98b3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.merge(pd.DataFrame({'Date':sorted(data['Date'].unique().tolist()*24),\n",
    "                         'Hour':list(range(0,24))*len(data['Date'].unique())}),\n",
    "                  on=['Date','Hour'],how='outer').\\\n",
    "fillna(0).sort_values(by=['Date','Hour'])\n",
    "\n",
    "data[data.columns[2:]] = data[data.columns[2:]].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45dfe474",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_flow = data.melt(id_vars=['Date','Hour']).fillna(0)\n",
    "od_flow['o'] = od_flow['variable'].apply(lambda x:x.split(' - ')[0])\n",
    "od_flow['d'] = od_flow['variable'].apply(lambda x:x.split(' - ')[1])\n",
    "\n",
    "\n",
    "outgoing_flow = od_flow.groupby(['Date','Hour','o']).agg({'value':sum}).reset_index()\n",
    "outgoing_flow.rename(columns={'o':'station','value':'outgoing_flow'},inplace=True)\n",
    "incoming_flow = od_flow.groupby(['Date','Hour','d']).agg({'value':sum}).reset_index()\n",
    "incoming_flow.rename(columns={'d':'station','value':'incoming_flow'},inplace=True)\n",
    "\n",
    "flow = incoming_flow.merge(outgoing_flow,on=['Date','Hour','station'])\n",
    "od = flow.pivot_table(values=['incoming_flow','outgoing_flow'],index=['Date','Hour'],\n",
    "                columns = 'station')\n",
    "col = od.columns\n",
    "od.columns = [i[0]+'-'+i[1] for i in col]\n",
    "od.to_csv('inout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55da5c",
   "metadata": {},
   "source": [
    "# different methods, all tested on 09-26 to 10-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b9de21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>incoming_flow-12TH</th>\n",
       "      <th>incoming_flow-16TH</th>\n",
       "      <th>incoming_flow-19TH</th>\n",
       "      <th>incoming_flow-24TH</th>\n",
       "      <th>incoming_flow-ANTC</th>\n",
       "      <th>incoming_flow-ASHB</th>\n",
       "      <th>incoming_flow-BALB</th>\n",
       "      <th>incoming_flow-BAYF</th>\n",
       "      <th>incoming_flow-BERY</th>\n",
       "      <th>incoming_flow-CAST</th>\n",
       "      <th>...</th>\n",
       "      <th>outgoing_flow-SANL</th>\n",
       "      <th>outgoing_flow-SBRN</th>\n",
       "      <th>outgoing_flow-SFIA</th>\n",
       "      <th>outgoing_flow-SHAY</th>\n",
       "      <th>outgoing_flow-SSAN</th>\n",
       "      <th>outgoing_flow-UCTY</th>\n",
       "      <th>outgoing_flow-WARM</th>\n",
       "      <th>outgoing_flow-WCRK</th>\n",
       "      <th>outgoing_flow-WDUB</th>\n",
       "      <th>outgoing_flow-WOAK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-09-01</th>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 incoming_flow-12TH  incoming_flow-16TH  incoming_flow-19TH  \\\n",
       "Date       Hour                                                               \n",
       "2022-09-01 0                   21.0                38.0                17.0   \n",
       "           1                    1.0                 3.0                 1.0   \n",
       "           2                    0.0                 0.0                 0.0   \n",
       "           3                    0.0                 0.0                 0.0   \n",
       "           4                    0.0                 0.0                 0.0   \n",
       "\n",
       "                 incoming_flow-24TH  incoming_flow-ANTC  incoming_flow-ASHB  \\\n",
       "Date       Hour                                                               \n",
       "2022-09-01 0                   48.0                29.0                38.0   \n",
       "           1                    2.0                13.0                 1.0   \n",
       "           2                    0.0                 5.0                 0.0   \n",
       "           3                    0.0                 0.0                 0.0   \n",
       "           4                    1.0                 3.0                 0.0   \n",
       "\n",
       "                 incoming_flow-BALB  incoming_flow-BAYF  incoming_flow-BERY  \\\n",
       "Date       Hour                                                               \n",
       "2022-09-01 0                   38.0                21.0               101.0   \n",
       "           1                    8.0                 2.0                 3.0   \n",
       "           2                    0.0                 0.0                 1.0   \n",
       "           3                    0.0                 0.0                 0.0   \n",
       "           4                    0.0                 0.0                 0.0   \n",
       "\n",
       "                 incoming_flow-CAST  ...  outgoing_flow-SANL  \\\n",
       "Date       Hour                      ...                       \n",
       "2022-09-01 0                   34.0  ...                10.0   \n",
       "           1                    2.0  ...                 0.0   \n",
       "           2                    0.0  ...                 0.0   \n",
       "           3                    0.0  ...                 0.0   \n",
       "           4                    0.0  ...                 0.0   \n",
       "\n",
       "                 outgoing_flow-SBRN  outgoing_flow-SFIA  outgoing_flow-SHAY  \\\n",
       "Date       Hour                                                               \n",
       "2022-09-01 0                    4.0                89.0                 2.0   \n",
       "           1                    1.0                10.0                 1.0   \n",
       "           2                    0.0                 2.0                 0.0   \n",
       "           3                    0.0                 0.0                 0.0   \n",
       "           4                    0.0                 1.0                 0.0   \n",
       "\n",
       "                 outgoing_flow-SSAN  outgoing_flow-UCTY  outgoing_flow-WARM  \\\n",
       "Date       Hour                                                               \n",
       "2022-09-01 0                    4.0                 4.0                12.0   \n",
       "           1                    1.0                 1.0                 1.0   \n",
       "           2                    0.0                 0.0                 0.0   \n",
       "           3                    0.0                 0.0                 0.0   \n",
       "           4                    0.0                 4.0                 2.0   \n",
       "\n",
       "                 outgoing_flow-WCRK  outgoing_flow-WDUB  outgoing_flow-WOAK  \n",
       "Date       Hour                                                              \n",
       "2022-09-01 0                    2.0                 4.0                 7.0  \n",
       "           1                    3.0                 0.0                 5.0  \n",
       "           2                    0.0                 0.0                 0.0  \n",
       "           3                    0.0                 0.0                 0.0  \n",
       "           4                    0.0                 0.0                 0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od = od.astype('float128')\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcbc4e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6606124503714431\n",
      "0.6201865778817927\n"
     ]
    }
   ],
   "source": [
    "### same as 1 hours before\n",
    "print(r2_score(od.iloc[-24*7-1:-1,],od.iloc[-24*7:,],multioutput='variance_weighted'))\n",
    "print(r2_score(od.iloc[-24*7-1:-1,].values,od.iloc[-24*7:,].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce820ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.4725\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(od.iloc[-24*7-1:-1,].values,od.iloc[-24*7:,].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53d874ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9088078785342216\n",
      "19.212797619047619046\n",
      "34.819948936320005026\n"
     ]
    }
   ],
   "source": [
    "### same as a week ago\n",
    "print(r2_score(od.iloc[-48*7:-24*7,].values,od.iloc[-24*7:,].values))\n",
    "print(mean_absolute_error(od.iloc[-48*7:-24*7,].values,od.iloc[-24*7:,].values))\n",
    "print(mean_squared_error(od.iloc[-48*7:-24*7,].values,od.iloc[-24*7:,].values,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbec6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = incoming_flow.merge(outgoing_flow,on=['Date','Hour','station'])\n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od['DOW'] = pd.to_datetime(od['Date'])\n",
    "od['DOW'] = od.DOW.dt.dayofweek\n",
    "od = pd.concat([od.drop(['DOW'],axis=1),\n",
    "                     pd.get_dummies(od['DOW'],prefix='dow',prefix_sep='-')],\n",
    "                   axis=1)\n",
    "od = pd.concat([od,\n",
    "                     pd.get_dummies(od['Hour'],prefix='hour',prefix_sep='-')],\n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b043275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample R2\n",
      "0.9658714587933703\n",
      "0.9656071130380675\n",
      "22.377527\n",
      "41.379025\n"
     ]
    }
   ],
   "source": [
    "### lag linear regression, many to one\n",
    "od = od.sort_values(by=['station','Date','Hour'])\n",
    "no_lag = 24*7\n",
    "\n",
    "for lag in range(1,no_lag+1):\n",
    "    temp = od[['station','incoming_flow','outgoing_flow']].shift(lag)\n",
    "    temp.columns = ['station'+'-'+str(lag),'incoming_flow'+'-'+str(lag),'outgoing_flow'+'-'+str(lag)]\n",
    "    od = pd.concat([od,temp],axis=1)\n",
    "    \n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od = od.dropna()\n",
    "od = od.loc[od['station']==od['station'+'-'+str(lag)]]\n",
    "\n",
    "x = od[[col for col in od.columns if '_flow-' in col]]\n",
    "y = od[['incoming_flow','outgoing_flow']]\n",
    "\n",
    "x_train = x.iloc[:-24*50*7,:].values\n",
    "y_train = y.iloc[:-24*50*7,].values\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(x_train, y_train)\n",
    "\n",
    "print('out of sample R2')\n",
    "x_test = x.iloc[-24*50*7:,:].values\n",
    "y_test = y.iloc[-24*50*7:].values\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(r2_score(y_pred.reshape(24*7*50,2),y_test.reshape(24*7*50,2),multioutput='variance_weighted'))\n",
    "print(mean_absolute_error(y_pred,y_test))\n",
    "print(mean_squared_error(y_pred,y_test,squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c17c91",
   "metadata": {},
   "source": [
    "## adding  surrounding flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80b6c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7544353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "od = incoming_flow.merge(outgoing_flow,on=['Date','Hour','station'])\n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od['DOW'] = pd.to_datetime(od['Date'])\n",
    "od['DOW'] = od.DOW.dt.dayofweek\n",
    "od = pd.concat([od.drop(['DOW'],axis=1),\n",
    "                     pd.get_dummies(od['DOW'],prefix='dow',prefix_sep='-')],\n",
    "                   axis=1)\n",
    "od = pd.concat([od,\n",
    "                     pd.get_dummies(od['Hour'],prefix='hour',prefix_sep='-')],\n",
    "                   axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b7d1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.iloc[:,5:] = od.iloc[:,5:].astype('float128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b9c05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adj matrix\n",
    "stations = od['station'].unique()\n",
    "stations_index = dict(zip(stations,range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f0928d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = ['ANTC','PCTR','PITT','NCON','CONC','PHIL','WCRK','LAFY',\n",
    "        'ORIN','ROCK','MCAR','19TH','12TH','WOAK','EMBR',\n",
    "        'MONT','POWL','CIVC','16TH','24TH','GLEN','BALB',\n",
    "        'DALY','COLM','SSAN','SBRN','MLBR','SFIA']\n",
    "orange = ['RICH','DELN','PLZA','NBRK','DBRK','ASHB','MCAR',\n",
    "          '19TH','12TH','LAKE','FTVL','COLS','SANL','BAYF',\n",
    "          'HAYW','SHAY','UCTY','FRMT','WARM','MLPT','BERY']\n",
    "red = ['RICH','DELN','PLZA','NBRK','DBRK','ASHB','MCAR',\n",
    "          '19TH','12TH','WOAK','EMBR',\n",
    "        'MONT','POWL','CIVC','16TH','24TH','GLEN','BALB',\n",
    "        'DALY','COLM','SSAN','SBRN','MLBR','SFIA']\n",
    "blue = ['DUBL','WDUB','CAST','BAYF','SANL','COLS','FTVL',\n",
    "        'LAKE','WOAK','EMBR','MONT','POWL','CIVC','16TH',\n",
    "        '24TH','GLEN','BALB','DALY']\n",
    "green = ['BERY','MLPT','WARM','FRMT','UCTY','SHAY','HAYW',\n",
    "         'BAYF','SANL','COLS','FTVL',\n",
    "        'LAKE','WOAK','EMBR','MONT','POWL','CIVC','16TH',\n",
    "        '24TH','GLEN','BALB','DALY']\n",
    "grey = ['COLS','OAKL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87474c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.zeros([50,50])\n",
    "for route in [yellow,orange,red,blue,green,grey]:\n",
    "    i = 0\n",
    "    for station in route:\n",
    "        if i+1 < len(route):\n",
    "            pair1 = stations_index[route[i]]\n",
    "            pair2 = stations_index[route[i+1]]\n",
    "            adj[pair1,pair2] = adj[pair1,pair2]+1\n",
    "            adj[pair2,pair1] = adj[pair2,pair1]+1\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e1da3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = {}\n",
    "for route in [yellow,orange,red,blue,green,grey]:\n",
    "    i = 0\n",
    "    for station in route:\n",
    "        if i+1 < len(route):\n",
    "            key = route[i]\n",
    "            value = route[i+1]\n",
    "            connection[key] = connection.get(key,[])+[value]\n",
    "            connection[value] = connection.get(value,[])+[key]\n",
    "            i += 1\n",
    "for key in connection.keys():\n",
    "    connection[key] = list(set(connection[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "873d8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_flow(x,od,connection):\n",
    "    date = x['Date']\n",
    "    hour = x['Hour']\n",
    "    source = x['station']\n",
    "    \n",
    "    temp = od.loc[(od['Date']==date)&\\\n",
    "                                    (od['Hour']==hour)]\n",
    "    nearby_flows = temp.loc[(temp['station'].isin(connection[source]))]\\\n",
    "                                    [['incoming_flow','outgoing_flow']].sum().values.tolist()\n",
    "\n",
    "    \n",
    "    return nearby_flows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218566ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_flow_list = Parallel(n_jobs=8)(delayed(get_nearby_flow)(od.iloc[i],od,connection) for i in range(len(od)))\n",
    "od[['nearby_incoming','nearby_outgoing']] = nearby_flow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf96ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "od['nearby_incoming'] = (od['nearby_incoming']+0.1)/(od['incoming_flow']+0.1)\n",
    "od['nearby_outgoing'] = (od['nearby_outgoing']+0.1)/(od['incoming_flow']+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a14c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = od.sort_values(by=['station','Date','Hour'])\n",
    "no_lag = 24*7\n",
    "for lag in range(1,no_lag+1):\n",
    "    temp = od[['station','incoming_flow','outgoing_flow','nearby_incoming','nearby_outgoing']].shift(lag)\n",
    "    temp.columns = ['station'+'-'+str(lag),\n",
    "                    'incoming_flow'+'-'+str(lag),'outgoing_flow'+'-'+str(lag),\n",
    "                    'nearby_incoming'+'-'+str(lag),'nearby_outgoing'+'-'+str(lag)]\n",
    "    od = pd.concat([od,temp],axis=1)\n",
    "    od['incoming_flow'+'-'+str(lag)] = (od['incoming_flow'+'-'+str(lag)]+0.1)/(od['incoming_flow']+0.1)\n",
    "    od['outgoing_flow'+'-'+str(lag)] = (od['outgoing_flow'+'-'+str(lag)]+0.1)/(od['incoming_flow']+0.1)\n",
    "    od['nearby_incoming'+'-'+str(lag)] = (od['nearby_incoming'+'-'+str(lag)]+0.1)/(od['incoming_flow']+0.1)\n",
    "    od['nearby_outgoing'+'-'+str(lag)] = (od['nearby_outgoing'+'-'+str(lag)]+0.1)/(od['incoming_flow']+0.1)\n",
    "    \n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od = od.dropna()\n",
    "od = od.loc[od['station']==od['station'+'-'+str(lag)]]\n",
    "od = od.drop(columns=[i for i in od.columns if 'station-' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad36e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.to_csv('OD_168_neighbor.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "220e8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample R2\n",
      "-3.0058086291145685\n",
      "-2.9952399813297865\n",
      "95.58156300187923\n",
      "203.12540831490435\n"
     ]
    }
   ],
   "source": [
    "od = pd.read_csv('OD_168_neighbor.csv')\n",
    "\n",
    "x = od[od.columns[5:]]\n",
    "y = od[['incoming_flow','outgoing_flow']]\n",
    "\n",
    "x_train = x.iloc[:-24*50*7,:].values\n",
    "y_train = y.iloc[:-24*50*7,].values\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(x_train, y_train)\n",
    "\n",
    "print('out of sample R2')\n",
    "x_test = x.iloc[-24*50*7:,:].values\n",
    "y_test = y.iloc[-24*50*7:].values\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(r2_score(y_pred.reshape(24*7*50,2),y_test.reshape(24*7*50,2),multioutput='variance_weighted'))\n",
    "print(mean_absolute_error(y_pred,y_test))\n",
    "print(mean_squared_error(y_pred,y_test,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90dbfbbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 569702044.6305478, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599579368.1648469, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 690074818.4409485, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 679591516.5574106, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 705538502.2583896, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 691657383.4602401, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599252052.0440828, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 679860318.9560418, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 572465537.5938339, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 707973449.862305, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 693069171.6053855, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599025995.9152611, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 679217036.221633, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 574987296.5553435, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 710032074.770885, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 694405600.4523767, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 598952836.1466768, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 678949838.466973, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 577288119.3544719, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 711643890.9314886, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 695720671.513899, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 598860040.4078896, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 678447236.4520929, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 579360240.872236, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 712843527.0851122, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 696996651.0986639, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599154605.7654983, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 677874672.6733183, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 581243923.2932562, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 713430306.4163955, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599728189.609541, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 698059489.6048515, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 678314485.1514018, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 582866986.9079924, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 714657053.7484239, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 698578563.7085371, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599661326.8147128, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 678669236.150245, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 583893093.4092805, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 715469515.3204937, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 698934602.616948, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 599453448.8960531, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 678083453.9381977, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 584895090.9976702, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 715812637.88584, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 699148060.4733139, tolerance: 169735.87804351852\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 598001957.3400906, tolerance: 147789.82768619794\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 677682285.1529809, tolerance: 168354.20647136576\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 585857794.3413984, tolerance: 140305.3694035185\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1950: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 715990334.0181866, tolerance: 174850.09336642938\n",
      "  cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiTaskLasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([0.01, 0.11, 0.21, 0.31, 0.41, 0.51, 0.61, 0.71, 0.81, 0.91]),\n",
       "                         'fit_intercept': [True]},\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regularization, LASSO\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parameters = {'alpha':np.arange(0.01,1,0.1), 'fit_intercept':[True]}\n",
    "lasso = MultiTaskLasso(max_iter=1000)\n",
    "lassocv = GridSearchCV(lasso, parameters,n_jobs=-1,scoring='neg_mean_absolute_error',verbose=3)\n",
    "lassocv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ef582bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.508738209715691\n",
      "95.4770053297275\n",
      "202.88609299410282\n"
     ]
    }
   ],
   "source": [
    "y_pred = lassocv.best_estimator_.predict(x_test)\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_pred,y_test))\n",
    "print(mean_squared_error(y_pred,y_test,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be8a8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 71 candidates, totalling 355 fits\n",
      "Best parameter (CV score=-101.642):\n",
      "{'pca__n_components': 702}\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "# set the tolerance to a large value to make the example faster\n",
    "regressor = LinearRegression()\n",
    "pipe = Pipeline(steps=[(\"pca\", pca), (\"regressor\", regressor)])\n",
    "\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    \"pca__n_components\": np.arange(2,705,10),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid,n_jobs=-1,scoring='neg_mean_absolute_error',verbose=3)\n",
    "search.fit(x_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c58c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.286028101268884\n",
      "99.04821761720204\n",
      "212.32559604209655\n"
     ]
    }
   ],
   "source": [
    "y_pred = search.best_estimator_.predict(x_test)\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_pred,y_test))\n",
    "print(mean_squared_error(y_pred,y_test,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b72e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(VNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Linear(input_size, n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,output_size),\n",
    "        )\n",
    " \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.layer1(x)        \n",
    "        return x\n",
    "\n",
    "def get_loss_and_metrics(model, batch, criterion, device):\n",
    "  # Implement forward pass and loss calculation for one batch.\n",
    "  # Remember to move the batch to device.\n",
    "  # \n",
    "  # Return a tuple:\n",
    "  # - loss for the batch (Tensor)\n",
    "  # - number of correctly classified examples in the batch (Tensor)\n",
    "    data, target = batch[0], batch[1]\n",
    "    data = torch.tensor(data)\n",
    "    target = torch.tensor(target)\n",
    "    \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(data.float())\n",
    "    loss = criterion(pred, target)\n",
    "    \n",
    "    \n",
    "    return (pred,target,loss)\n",
    "    \n",
    "def step(loss, optimizer):\n",
    "  # Implement backward pass and update.\n",
    "\n",
    "  # TODO\n",
    "    loss = loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026ed6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = od.iloc[:-24*50*7,5:].values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(fts)\n",
    "fts = torch.tensor(scaler.transform(fts))\n",
    "target = torch.tensor(od.iloc[:-24*50*7,3:5].values)                      \n",
    "train_dataset = torch.utils.data.TensorDataset(fts,target)\n",
    "                      \n",
    "fts_val = torch.tensor(scaler.transform(od.iloc[-24*50*7:,5:].values))                   \n",
    "target_val = torch.tensor(od.iloc[-24*50*7:,3:5].values)                      \n",
    "validation_dataset = torch.utils.data.TensorDataset(fts_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07735b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss:49.9111 validation_mae:9.6309 validation R2: 0.8178: 100%|â–ˆ| 5000/500\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "N_EPOCHS = 5000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=len(validation_dataset),\n",
    "                                                    num_workers=0)\n",
    "model = VNN(input_size=od.shape[1]-5,n_feature=64,output_size=2)\n",
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001) \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "pbar = tqdm(range(N_EPOCHS))\n",
    "\n",
    "validation_mae = 99999999\n",
    "for i in pbar: \n",
    "    while validation_mae > 10:\n",
    "        total_train_loss = 0.0\n",
    "        total_train_mae = 0.0\n",
    "        total_train_r2 = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            y_pred,y_true,loss = get_loss_and_metrics(model, batch, criterion, device)\n",
    "            step(loss.float(), optimizer)\n",
    "            total_train_loss += loss.item()\n",
    "            size = y_pred.shape[0]\n",
    "            mae = mean_absolute_error(y_pred.detach().numpy(),y_true.detach().numpy())\n",
    "            r2 = r2_score(y_pred.view(size,2).detach().numpy(),y_true.view(size,2).detach().numpy())\n",
    "            total_train_mae += mae\n",
    "            total_train_r2 += r2\n",
    "\n",
    "        with torch.no_grad():       \n",
    "            y_pred,y_true,loss = get_loss_and_metrics(model, batch, criterion, device)\n",
    "            total_validation_loss += loss.item()\n",
    "            size = y_pred.shape[0]\n",
    "            validation_mae = mean_absolute_error(y_pred.view(size,2).detach().numpy(),y_true.view(size,2).detach().numpy())\n",
    "            validation_r2 = r2_score(y_pred.view(size,2).detach().numpy(),y_true.view(size,2).detach().numpy())\n",
    "\n",
    "\n",
    "        mean_train_loss = total_train_loss / len(train_dataloader)\n",
    "        train_mae = total_train_mae / len(train_dataloader)\n",
    "        train_r2 = total_train_r2 / len(train_dataloader)\n",
    "\n",
    "        mean_validation_loss = total_validation_loss / len(validation_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "        pbar.set_description('train_loss:'+ str(round(mean_train_loss,4))+ \\\n",
    "                             ' validation_mae:'+ str(round(validation_mae,4)) +\\\n",
    "                            ' validation R2: '+ str(round(validation_r2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "642ead66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.750567010181815"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred.view(size,2).detach().numpy(),y_true.view(size,2).detach().numpy(),squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1e6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
