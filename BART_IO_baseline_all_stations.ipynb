{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc05a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import * \n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_absolute_percentage_error,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import geopandas as gpd\n",
    "# from geopy.distance import distance,geodesic\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf, pacf,adfuller, kpss,range_unit_root_test\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6f0d82e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# please download data at https://www.dropbox.com/s/uquijy335rg0kjn/date-hour-soo-dest-2022.csv.gz?dl=0\n",
    "data = pd.read_csv('date-hour-soo-dest-2022.csv.gz',compression='gzip',header=None)\n",
    "data.columns = ['Date', 'Hour', 'Origin', 'Destination', 'Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c53f8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Date'].apply(lambda x: x.split('-')[1])\n",
    "# data = data.loc[data['Month'].isin(['09','10'])]\n",
    "data['OD'] = data['Origin'] + ' - ' + data['Destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d59ca589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.pivot_table(data,index=['Date','Hour'],columns=['OD'],fill_value=0).reset_index()\n",
    "data.columns = [i[1] if i[0]=='Number' else i[0] for i in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d98b3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.merge(pd.DataFrame({'Date':sorted(data['Date'].unique().tolist()*24),\n",
    "                         'Hour':list(range(0,24))*len(data['Date'].unique())}),\n",
    "                  on=['Date','Hour'],how='outer').\\\n",
    "fillna(0).sort_values(by=['Date','Hour'])\n",
    "\n",
    "data[data.columns[2:]] = data[data.columns[2:]].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844eb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in data.columns[2:]:\n",
    "    plt.plot(data['Date'],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe = data[data.columns[2:]].describe()\n",
    "plt.plot(describe.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "45dfe474",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_flow = data.melt(id_vars=['Date','Hour']).fillna(0)\n",
    "od_flow['o'] = od_flow['variable'].apply(lambda x:x.split(' - ')[0])\n",
    "od_flow['d'] = od_flow['variable'].apply(lambda x:x.split(' - ')[1])\n",
    "\n",
    "\n",
    "outgoing_flow = od_flow.groupby(['Date','Hour','o']).agg({'value':sum}).reset_index()\n",
    "outgoing_flow.rename(columns={'o':'station','value':'outgoing_flow'},inplace=True)\n",
    "incoming_flow = od_flow.groupby(['Date','Hour','d']).agg({'value':sum}).reset_index()\n",
    "incoming_flow.rename(columns={'d':'station','value':'incoming_flow'},inplace=True)\n",
    "\n",
    "od = incoming_flow.merge(outgoing_flow,on=['Date','Hour','station'])\n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od['DOW'] = pd.to_datetime(od['Date'])\n",
    "od['DOW'] = od.DOW.dt.dayofweek\n",
    "od = pd.concat([od.drop(['DOW'],axis=1),\n",
    "                     pd.get_dummies(od['DOW'],prefix='dow',prefix_sep='-')],\n",
    "                   axis=1)\n",
    "od = pd.concat([od,\n",
    "                     pd.get_dummies(od['Hour'],prefix='hour',prefix_sep='-')],\n",
    "                   axis=1)\n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od.to_csv('inoutlong.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "02b9de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = incoming_flow.merge(outgoing_flow,on=['Date','Hour','station'])\n",
    "od = flow.pivot_table(values=['incoming_flow','outgoing_flow'],index=['Date','Hour'],\n",
    "                columns = 'station')\n",
    "col = od.columns\n",
    "od.columns = [i[0]+'-'+i[1] for i in col]\n",
    "\n",
    "od.to_csv('inoutwide.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55da5c",
   "metadata": {},
   "source": [
    "# different methods, all tested on 09-26 to 10-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0988005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_MAPE(v, v_, axis=None):\n",
    "    '''\n",
    "    Mean absolute percentage error.\n",
    "    :param v: np.ndarray or int, ground truth.\n",
    "    :param v_: np.ndarray or int, prediction.\n",
    "    :param axis: axis to do calculation.\n",
    "    :return: int, MAPE averages on all elements of input.\n",
    "    '''\n",
    "    mask = (v == 0)\n",
    "    percentage = np.abs(v_ - v) / np.abs(v)\n",
    "    if np.any(mask):\n",
    "        masked_array = np.ma.masked_array(percentage, mask=mask)  # mask the dividing-zero as invalid\n",
    "        result = masked_array.mean(axis=axis)\n",
    "        if isinstance(result, np.ma.MaskedArray):\n",
    "            return result.filled(np.nan)\n",
    "        else:\n",
    "            return result\n",
    "    return np.mean(percentage, axis).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcbc4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### same as a week ago\n",
    "od = pd.read_csv('inoutlong.csv')\n",
    "y_pred = od.iloc[-24*7*2*50:-24*7*50,3:5]\n",
    "y_test = od.iloc[-24*7*50:,3:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75f2447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9489373219533752\n",
      "19.21297619047619\n",
      "50.05978277945785\n",
      "0.22577725021459194\n",
      "0.31858051751140515\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False))\n",
    "\n",
    "\n",
    "print(np.mean(mean_squared_error(y_test,y_pred,multioutput='raw_values',squared=False)/np.std(y_test)))\n",
    "y_pred = np.array(y_pred['incoming_flow'].values.tolist()+y_pred['outgoing_flow'].values.tolist())\n",
    "y_test = np.array(y_test['incoming_flow'].values.tolist()+y_test['outgoing_flow'].values.tolist())\n",
    "print(masked_MAPE(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e661c6",
   "metadata": {},
   "source": [
    "# station-level incoming/outgoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b043275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample R2\n",
      "0.9698645501199167\n",
      "20.590320932259978\n",
      "38.16478599960493\n",
      "0.17222992996315434\n",
      "0.6901845375521896\n"
     ]
    }
   ],
   "source": [
    "## lag linear regression, many to one\n",
    "od = pd.read_csv('inoutlong.csv')\n",
    "od = od.sort_values(by=['station','Date','Hour'])\n",
    "no_lag = 24*7\n",
    "\n",
    "for lag in range(1,no_lag+1):\n",
    "    temp = od[['station','incoming_flow','outgoing_flow']].shift(lag)\n",
    "    temp.columns = ['station'+'-'+str(lag),'incoming_flow'+'-'+str(lag),'outgoing_flow'+'-'+str(lag)]\n",
    "    od = pd.concat([od,temp],axis=1)\n",
    "    \n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od = od.dropna()\n",
    "od = od.loc[od['station']==od['station'+'-'+str(lag)]]\n",
    "\n",
    "x = od[[col for col in od.columns if '_flow-' in col]]\n",
    "y = od[['incoming_flow','outgoing_flow']]\n",
    "\n",
    "x_train = x.iloc[:-24*50*7,:].values\n",
    "y_train = y.iloc[:-24*50*7,].values\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(x_train, y_train)\n",
    "\n",
    "print('out of sample R2')\n",
    "x_test = x.iloc[-24*50*7:,:].values\n",
    "# x_test = scaler.transform(x_test)\n",
    "y_test = y.iloc[-24*50*7:].values\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False))\n",
    "print(np.mean(mean_squared_error(y_test,y_pred,multioutput='raw_values',squared=False)/np.std(y_test)))\n",
    "print(masked_MAPE(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec5ecfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample R2\n",
      "0.9717966032934099\n",
      "18.254343657666197\n",
      "36.40979942499047\n",
      "0.16431003189703514\n",
      "0.548281513983181\n"
     ]
    }
   ],
   "source": [
    "## lag linear regression, many to one\n",
    "od = pd.read_csv('inoutlong.csv')\n",
    "od = od.sort_values(by=['station','Date','Hour'])\n",
    "no_lag = 24*7\n",
    "# 48 continuous hourly lag, 3-7 days ago same hour-of-day lag, 7 weeks ago lag\n",
    "for lag in list(range(1,48))+list(np.array(list(range(3,8)))*24)+list(np.array(list(range(2,8)))*24*7):\n",
    "    temp = od[['station','incoming_flow','outgoing_flow']].shift(lag)\n",
    "    temp.columns = ['station'+'-'+str(lag),'incoming_flow'+'-'+str(lag),'outgoing_flow'+'-'+str(lag)]\n",
    "    od = pd.concat([od,temp],axis=1)\n",
    "    \n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od = od.dropna()\n",
    "od = od.loc[od['station']==od['station'+'-'+str(lag)]]\n",
    "\n",
    "x = od[[col for col in od.columns if '_flow-' in col]]\n",
    "y = od[['incoming_flow','outgoing_flow']]\n",
    "\n",
    "x_train = x.iloc[:-24*50*7,:].values\n",
    "y_train = y.iloc[:-24*50*7,].values\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(x_train, y_train)\n",
    "\n",
    "print('out of sample R2')\n",
    "x_test = x.iloc[-24*50*7:,:].values\n",
    "y_test = y.iloc[-24*50*7:].values\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False))\n",
    "print(np.mean(mean_squared_error(y_test,y_pred,multioutput='raw_values',squared=False)/np.std(y_test)))\n",
    "print(masked_MAPE(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c17c91",
   "metadata": {},
   "source": [
    "## adding  surrounding flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b6c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b7544353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch_geometric\n",
    "# from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "od = pd.read_csv('inoutlong.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "6b7d1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.iloc[:,5:] = od.iloc[:,5:].astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b9c05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adj matrix\n",
    "stations = od['station'].unique()\n",
    "stations_index = dict(zip(stations,range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5f0928d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = ['ANTC','PCTR','PITT','NCON','CONC','PHIL','WCRK','LAFY',\n",
    "        'ORIN','ROCK','MCAR','19TH','12TH','WOAK','EMBR',\n",
    "        'MONT','POWL','CIVC','16TH','24TH','GLEN','BALB',\n",
    "        'DALY','COLM','SSAN','SBRN','MLBR','SFIA']\n",
    "orange = ['RICH','DELN','PLZA','NBRK','DBRK','ASHB','MCAR',\n",
    "          '19TH','12TH','LAKE','FTVL','COLS','SANL','BAYF',\n",
    "          'HAYW','SHAY','UCTY','FRMT','WARM','MLPT','BERY']\n",
    "red = ['RICH','DELN','PLZA','NBRK','DBRK','ASHB','MCAR',\n",
    "          '19TH','12TH','WOAK','EMBR',\n",
    "        'MONT','POWL','CIVC','16TH','24TH','GLEN','BALB',\n",
    "        'DALY','COLM','SSAN','SBRN','MLBR','SFIA']\n",
    "blue = ['DUBL','WDUB','CAST','BAYF','SANL','COLS','FTVL',\n",
    "        'LAKE','WOAK','EMBR','MONT','POWL','CIVC','16TH',\n",
    "        '24TH','GLEN','BALB','DALY']\n",
    "green = ['BERY','MLPT','WARM','FRMT','UCTY','SHAY','HAYW',\n",
    "         'BAYF','SANL','COLS','FTVL',\n",
    "        'LAKE','WOAK','EMBR','MONT','POWL','CIVC','16TH',\n",
    "        '24TH','GLEN','BALB','DALY']\n",
    "grey = ['COLS','OAKL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "87474c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.zeros([50,50])\n",
    "for route in [yellow,orange,red,blue,green,grey]:\n",
    "    i = 0\n",
    "    for station in route:\n",
    "        if i+1 < len(route):\n",
    "            pair1 = stations_index[route[i]]\n",
    "            pair2 = stations_index[route[i+1]]\n",
    "            adj[pair1,pair2] = adj[pair1,pair2]+1\n",
    "            adj[pair2,pair1] = adj[pair2,pair1]+1\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5e1da3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = {}\n",
    "for route in [yellow,orange,red,blue,green,grey]:\n",
    "    i = 0\n",
    "    for station in route:\n",
    "        if i+1 < len(route):\n",
    "            key = route[i]\n",
    "            value = route[i+1]\n",
    "            connection[key] = connection.get(key,[])+[value]\n",
    "            connection[value] = connection.get(value,[])+[key]\n",
    "            i += 1\n",
    "for key in connection.keys():\n",
    "    connection[key] = list(set(connection[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "873d8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_flow(x,od,connection):\n",
    "    date = x['Date']\n",
    "    hour = x['Hour']\n",
    "    source = x['station']\n",
    "    \n",
    "    temp = od.loc[(od['Date']==date)&\\\n",
    "                                    (od['Hour']==hour)]\n",
    "    nearby_flows = temp.loc[(temp['station'].isin(connection[source]))]\\\n",
    "                                    [['incoming_flow','outgoing_flow']].sum().values.tolist()\n",
    "\n",
    "    \n",
    "    return nearby_flows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "218566ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_flow_list = Parallel(n_jobs=8)(delayed(get_nearby_flow)(od.iloc[i],od,connection) for i in range(len(od)))\n",
    "od[['nearby_incoming','nearby_outgoing']] = nearby_flow_list\n",
    "# od['nearby_incoming'] = (od['nearby_incoming']+1e-6)/(od['incoming_flow']+1e-6)\n",
    "# od['nearby_outgoing'] = (od['nearby_outgoing']+1e-6)/(od['incoming_flow']+1e-6)\n",
    "od.to_csv('inoutlongNear.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8736c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = pd.read_csv('inoutlongNear.csv')\n",
    "od['month'] = od['Date'].apply(lambda x: x.split('-')[1])\n",
    "od = od.loc[od['month'].isin(['09','10'])]\n",
    "del od['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "1a14c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = pd.read_csv('inoutlongNear.csv')\n",
    "od['month'] = od['Date'].apply(lambda x: x.split('-')[1])\n",
    "od = od.loc[od['month'].isin(['09','10'])]\n",
    "del od['month']\n",
    "od = od.sort_values(by=['station','Date','Hour'])\n",
    "no_lag = 24*7\n",
    "for lag in list(range(1,168)):#+list(np.array(list(range(3,8)))*24)+list(np.array(list(range(2,8)))*24*7):\n",
    "    temp = od[['station','incoming_flow','outgoing_flow','nearby_incoming','nearby_outgoing']].shift(lag)\n",
    "    temp.columns = ['station'+'-'+str(lag),\n",
    "                    'incoming_flow'+'-'+str(lag),'outgoing_flow'+'-'+str(lag),\n",
    "                    'nearby_incoming'+'-'+str(lag),'nearby_outgoing'+'-'+str(lag)]\n",
    "    od = pd.concat([od,temp],axis=1)\n",
    "#     od['incoming_flow'+'-'+str(lag)] = (od['incoming_flow'+'-'+str(lag)]+1e-5)/(od['incoming_flow']+1e-5)\n",
    "#     od['outgoing_flow'+'-'+str(lag)] = (od['outgoing_flow'+'-'+str(lag)]+1e-5)/(od['incoming_flow']+1e-5)\n",
    "#     od['nearby_incoming'+'-'+str(lag)] = (od['nearby_incoming'+'-'+str(lag)]+1e-5)/(od['incoming_flow']+1e-5)\n",
    "#     od['nearby_outgoing'+'-'+str(lag)] = (od['nearby_outgoing'+'-'+str(lag)]+1e-5)/(od['incoming_flow']+1e-5)\n",
    "    \n",
    "od = od.sort_values(by=['Date','Hour','station'])\n",
    "od = od.dropna()\n",
    "od = od.loc[od['station']==od['station'+'-'+str(lag)]]\n",
    "od = od.drop(columns=[i for i in od.columns if 'station-' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "220e8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample R2\n",
      "0.9699310583412695\n",
      "21.210490879505542\n",
      "38.25263828654556\n",
      "0.0007832197277821417\n",
      "0.79857519427667\n"
     ]
    }
   ],
   "source": [
    "x = od[od.columns[5:]]\n",
    "y = od[['incoming_flow','outgoing_flow']]\n",
    "\n",
    "x_train = x.iloc[:-24*50*7,:].values\n",
    "y_train = y.iloc[:-24*50*7,].values\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(x_train, y_train)\n",
    "\n",
    "print('out of sample R2')\n",
    "x_test = x.iloc[-24*50*7:,:].values\n",
    "y_test = y.iloc[-24*50*7:].values\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False)/np.mean(np.var(y_pred)))\n",
    "print(masked_MAPE(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90dbfbbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53896716.604298115, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4936555.941474974, tolerance: 1381929.2449206715\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69710470.15834802, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31060216.411984146, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6400158.505509675, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 249323413.41260985, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9498981.217228174, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51508179.011737704, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2874282.6485444903, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20549735.130452335, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..alpha=0.11, fit_intercept=True;, score=-12.811 total time= 4.9min\n",
      "[CV 5/5] END ..alpha=0.11, fit_intercept=True;, score=-17.818 total time= 4.2min\n",
      "[CV 4/5] END alpha=0.31000000000000005, fit_intercept=True;, score=-15.446 total time= 4.3min\n",
      "[CV 2/5] END ..alpha=0.51, fit_intercept=True;, score=-14.722 total time=20.2min\n",
      "[CV 4/5] END alpha=0.6100000000000001, fit_intercept=True;, score=-15.437 total time=24.5min\n",
      "[CV 3/5] END ..alpha=0.81, fit_intercept=True;, score=-16.305 total time=24.6min\n",
      "[CV 4/5] END ..alpha=0.01, fit_intercept=True;, score=-15.460 total time= 5.2min\n",
      "[CV 1/5] END alpha=0.31000000000000005, fit_intercept=True;, score=-12.813 total time= 4.4min\n",
      "[CV 4/5] END alpha=0.41000000000000003, fit_intercept=True;, score=-15.443 total time= 4.3min\n",
      "[CV 1/5] END alpha=0.6100000000000001, fit_intercept=True;, score=-12.805 total time=21.2min\n",
      "[CV 5/5] END alpha=0.7100000000000001, fit_intercept=True;, score=-17.802 total time=23.4min\n",
      "[CV 4/5] END ..alpha=0.81, fit_intercept=True;, score=-15.431 total time=24.2min\n",
      "[CV 2/5] END ..alpha=0.11, fit_intercept=True;, score=-14.729 total time= 5.0min\n",
      "[CV 3/5] END alpha=0.21000000000000002, fit_intercept=True;, score=-16.326 total time= 3.7min\n",
      "[CV 3/5] END alpha=0.31000000000000005, fit_intercept=True;, score=-16.323 total time= 4.4min\n",
      "[CV 1/5] END ..alpha=0.51, fit_intercept=True;, score=-12.807 total time=20.6min\n",
      "[CV 5/5] END alpha=0.6100000000000001, fit_intercept=True;, score=-17.806 total time=23.5min\n",
      "[CV 1/5] END ..alpha=0.81, fit_intercept=True;, score=-12.800 total time=24.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11024092.516472101, tolerance: 1476914.6717150856\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41410911.58001834, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23680303.62540537, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3972541.84138155, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1715690.6129601002, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..alpha=0.01, fit_intercept=True;, score=-17.838 total time= 5.1min\n",
      "[CV 4/5] END alpha=0.21000000000000002, fit_intercept=True;, score=-15.449 total time= 4.2min\n",
      "[CV 5/5] END alpha=0.31000000000000005, fit_intercept=True;, score=-17.818 total time= 4.3min\n",
      "[CV 3/5] END ..alpha=0.51, fit_intercept=True;, score=-16.316 total time=20.7min\n",
      "[CV 3/5] END alpha=0.7100000000000001, fit_intercept=True;, score=-16.309 total time=25.2min\n",
      "[CV 2/5] END ..alpha=0.91, fit_intercept=True;, score=-14.708 total time=37.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117893577.5914138, tolerance: 1381929.2449206715\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 107732228.89321733, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11955787.686276317, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7685196.301803768, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..alpha=0.01, fit_intercept=True;, score=-12.861 total time= 5.1min\n",
      "[CV 5/5] END alpha=0.21000000000000002, fit_intercept=True;, score=-17.823 total time= 4.4min\n",
      "[CV 2/5] END alpha=0.41000000000000003, fit_intercept=True;, score=-14.726 total time= 4.3min\n",
      "[CV 4/5] END ..alpha=0.51, fit_intercept=True;, score=-15.440 total time=20.6min\n",
      "[CV 4/5] END alpha=0.7100000000000001, fit_intercept=True;, score=-15.434 total time=24.9min\n",
      "[CV 1/5] END ..alpha=0.91, fit_intercept=True;, score=-12.797 total time=37.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246810953.52986705, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39440034.5537613, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25024586.72393155, tolerance: 1472714.7403256302\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..alpha=0.01, fit_intercept=True;, score=-14.746 total time= 5.0min\n",
      "[CV 2/5] END alpha=0.21000000000000002, fit_intercept=True;, score=-14.733 total time= 4.5min\n",
      "[CV 3/5] END alpha=0.41000000000000003, fit_intercept=True;, score=-16.319 total time= 4.4min\n",
      "[CV 2/5] END alpha=0.6100000000000001, fit_intercept=True;, score=-14.719 total time=20.3min\n",
      "[CV 1/5] END alpha=0.7100000000000001, fit_intercept=True;, score=-12.802 total time=25.4min\n",
      "[CV 3/5] END ..alpha=0.91, fit_intercept=True;, score=-16.302 total time=37.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 160915703.4879189, tolerance: 1476914.6717150856\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3465901.785875678, tolerance: 1476914.6717150856\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16009649.22020781, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2181346.6147206426, tolerance: 1569567.7504077854\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:2504: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5409054.030229628, tolerance: 1407546.5367371005\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MultiTaskLasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: array([0.01, 0.11, 0.21, 0.31, 0.41, 0.51, 0.61, 0.71, 0.81, 0.91]),\n",
       "                         &#x27;fit_intercept&#x27;: [True]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MultiTaskLasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: array([0.01, 0.11, 0.21, 0.31, 0.41, 0.51, 0.61, 0.71, 0.81, 0.91]),\n",
       "                         &#x27;fit_intercept&#x27;: [True]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultiTaskLasso</label><div class=\"sk-toggleable__content\"><pre>MultiTaskLasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiTaskLasso</label><div class=\"sk-toggleable__content\"><pre>MultiTaskLasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MultiTaskLasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': array([0.01, 0.11, 0.21, 0.31, 0.41, 0.51, 0.61, 0.71, 0.81, 0.91]),\n",
       "                         'fit_intercept': [True]},\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regularization, LASSO\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parameters = {'alpha':np.arange(0.01,1,0.1), 'fit_intercept':[True]}\n",
    "lasso = MultiTaskLasso(max_iter=1000)\n",
    "lassocv = GridSearchCV(lasso, parameters,n_jobs=-1,scoring='neg_mean_absolute_error',verbose=3)\n",
    "lassocv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8ef582bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977831859107926\n",
      "16.67924115477344\n",
      "32.58685761143001\n",
      "0.0006799193178248865\n",
      "0.49581757448573666\n"
     ]
    }
   ],
   "source": [
    "y_pred = lassocv.best_estimator_.predict(x_test)\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False)/np.mean(np.var(y_pred)))\n",
    "print(masked_MAPE(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be8a8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 71 candidates, totalling 355 fits\n",
      "Best parameter (CV score=-15.442):\n",
      "{'pca__n_components': 242}\n",
      "[CV 1/5] END .............pca__n_components=2;, score=-54.794 total time=   8.8s\n",
      "[CV 5/5] END ............pca__n_components=12;, score=-45.330 total time=   7.2s\n",
      "[CV 3/5] END ............pca__n_components=32;, score=-25.062 total time=  10.1s\n",
      "[CV 1/5] END ............pca__n_components=52;, score=-16.309 total time=  12.6s\n",
      "[CV 4/5] END ............pca__n_components=62;, score=-19.636 total time=   9.9s\n",
      "[CV 2/5] END ............pca__n_components=82;, score=-16.998 total time=  14.1s\n",
      "[CV 4/5] END ............pca__n_components=92;, score=-17.516 total time=  17.2s\n",
      "[CV 1/5] END ...........pca__n_components=112;, score=-13.178 total time=  15.7s\n",
      "[CV 5/5] END ...........pca__n_components=122;, score=-18.614 total time=  22.5s\n",
      "[CV 2/5] END ...........pca__n_components=142;, score=-15.029 total time=  23.2s\n",
      "[CV 1/5] END ...........pca__n_components=162;, score=-13.023 total time=  29.4s\n",
      "[CV 4/5] END ...........pca__n_components=172;, score=-15.998 total time=  24.6s\n",
      "[CV 2/5] END ...........pca__n_components=192;, score=-15.093 total time=  35.1s\n",
      "[CV 5/5] END ...........pca__n_components=202;, score=-18.193 total time=  35.9s\n",
      "[CV 1/5] END ...........pca__n_components=232;, score=-12.830 total time=  17.0s\n",
      "[CV 4/5] END ...........pca__n_components=242;, score=-15.458 total time=  17.6s\n",
      "[CV 2/5] END ...........pca__n_components=262;, score=-14.761 total time=  14.2s\n",
      "[CV 3/5] END ...............pca__n_components=432;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=442;, score=nan total time=   0.4s\n",
      "[CV 1/5] END ...............pca__n_components=462;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=472;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=492;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=502;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=522;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=532;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=562;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=582;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=582;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=602;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=622;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=632;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=662;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=672;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=682;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ............pca__n_components=12;, score=-33.450 total time=  11.1s\n",
      "[CV 4/5] END ............pca__n_components=22;, score=-30.970 total time=  11.1s\n",
      "[CV 2/5] END ............pca__n_components=42;, score=-19.790 total time=  12.7s\n",
      "[CV 5/5] END ............pca__n_components=52;, score=-22.613 total time=  10.6s\n",
      "[CV 3/5] END ............pca__n_components=72;, score=-19.775 total time=  10.6s\n",
      "[CV 1/5] END ............pca__n_components=92;, score=-14.142 total time=  17.1s\n",
      "[CV 4/5] END ...........pca__n_components=102;, score=-16.663 total time=  15.0s\n",
      "[CV 2/5] END ...........pca__n_components=122;, score=-15.056 total time=  18.7s\n",
      "[CV 5/5] END ...........pca__n_components=132;, score=-18.521 total time=  22.6s\n",
      "[CV 3/5] END ...........pca__n_components=152;, score=-17.038 total time=  30.5s\n",
      "[CV 1/5] END ...........pca__n_components=172;, score=-13.008 total time=  24.4s\n",
      "[CV 4/5] END ...........pca__n_components=182;, score=-15.889 total time=  31.9s\n",
      "[CV 2/5] END ...........pca__n_components=202;, score=-14.945 total time=  38.5s\n",
      "[CV 2/5] END ...........pca__n_components=222;, score=-14.815 total time=  14.8s\n",
      "[CV 5/5] END ...........pca__n_components=232;, score=-17.845 total time=  17.8s\n",
      "[CV 3/5] END ...........pca__n_components=252;, score=-16.357 total time=  16.0s\n",
      "[CV 1/5] END ...............pca__n_components=272;, score=nan total time=   0.6s\n",
      "[CV 2/5] END ...............pca__n_components=272;, score=nan total time=   0.4s\n",
      "[CV 3/5] END ...............pca__n_components=272;, score=nan total time=   0.4s\n",
      "[CV 4/5] END ...............pca__n_components=272;, score=nan total time=   0.4s\n",
      "[CV 5/5] END ...............pca__n_components=272;, score=nan total time=   0.4s\n",
      "[CV 1/5] END ...............pca__n_components=282;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=282;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=282;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=282;, score=nan total time=   0.4s\n",
      "[CV 5/5] END ...............pca__n_components=282;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=292;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=292;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=302;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=312;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=312;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=322;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=322;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=332;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=342;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=342;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=352;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=352;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=362;, score=nan total time=   0.4s\n",
      "[CV 3/5] END ...............pca__n_components=372;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=382;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=392;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=392;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=402;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=412;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=422;, score=nan total time=   0.2s\n",
      "[CV 5/5] END ...............pca__n_components=422;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=442;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=452;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=472;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=482;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=502;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=512;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=522;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=542;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=552;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=562;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=592;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=612;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=612;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=642;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=662;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=662;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=682;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=692;, score=nan total time=   0.3s\n",
      "[CV 2/5] END .............pca__n_components=2;, score=-63.425 total time=   5.8s\n",
      "[CV 4/5] END ............pca__n_components=12;, score=-39.734 total time=   9.2s\n",
      "[CV 2/5] END ............pca__n_components=32;, score=-21.831 total time=   7.8s\n",
      "[CV 4/5] END ............pca__n_components=42;, score=-22.019 total time=  12.1s\n",
      "[CV 1/5] END ............pca__n_components=62;, score=-15.831 total time=  13.4s\n",
      "[CV 5/5] END ............pca__n_components=72;, score=-21.305 total time=  12.5s\n",
      "[CV 3/5] END ............pca__n_components=92;, score=-19.247 total time=  19.1s\n",
      "[CV 2/5] END ...........pca__n_components=112;, score=-15.047 total time=  17.1s\n",
      "[CV 1/5] END ...........pca__n_components=132;, score=-13.032 total time=  22.3s\n",
      "[CV 4/5] END ...........pca__n_components=142;, score=-16.077 total time=  21.9s\n",
      "[CV 2/5] END ...........pca__n_components=162;, score=-15.187 total time=  29.5s\n",
      "[CV 5/5] END ...........pca__n_components=172;, score=-18.478 total time=  25.9s\n",
      "[CV 3/5] END ...........pca__n_components=192;, score=-16.705 total time=  37.9s\n",
      "[CV 1/5] END ...........pca__n_components=212;, score=-12.950 total time=  17.1s\n",
      "[CV 5/5] END ...........pca__n_components=212;, score=-18.097 total time=  15.1s\n",
      "[CV 3/5] END ...........pca__n_components=232;, score=-16.345 total time=  16.1s\n",
      "[CV 5/5] END ...........pca__n_components=242;, score=-17.836 total time=  18.0s\n",
      "[CV 3/5] END ...........pca__n_components=262;, score=-16.381 total time=  14.3s\n",
      "[CV 2/5] END ...............pca__n_components=452;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=462;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=482;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=502;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=512;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=522;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=552;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=552;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=572;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=592;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=612;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=622;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=642;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=652;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=662;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=692;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=702;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ............pca__n_components=12;, score=-38.133 total time=  12.9s\n",
      "[CV 1/5] END ............pca__n_components=32;, score=-19.421 total time=  10.3s\n",
      "[CV 5/5] END ............pca__n_components=42;, score=-24.225 total time=  12.0s\n",
      "[CV 3/5] END ............pca__n_components=62;, score=-20.954 total time=  11.5s\n",
      "[CV 4/5] END ............pca__n_components=72;, score=-18.766 total time=   9.5s\n",
      "[CV 2/5] END ............pca__n_components=92;, score=-16.270 total time=  17.3s\n",
      "[CV 5/5] END ...........pca__n_components=102;, score=-19.701 total time=  16.3s\n",
      "[CV 3/5] END ...........pca__n_components=122;, score=-17.254 total time=  20.5s\n",
      "[CV 1/5] END ...........pca__n_components=142;, score=-13.025 total time=  22.5s\n",
      "[CV 4/5] END ...........pca__n_components=152;, score=-16.026 total time=  30.4s\n",
      "[CV 2/5] END ...........pca__n_components=172;, score=-15.084 total time=  28.5s\n",
      "[CV 5/5] END ...........pca__n_components=182;, score=-18.432 total time=  29.8s\n",
      "[CV 3/5] END ...........pca__n_components=202;, score=-16.675 total time=  35.2s\n",
      "[CV 3/5] END ...........pca__n_components=222;, score=-16.467 total time=  15.3s\n",
      "[CV 1/5] END ...........pca__n_components=242;, score=-12.825 total time=  17.9s\n",
      "[CV 4/5] END ...........pca__n_components=252;, score=-15.459 total time=  17.4s\n",
      "[CV 1/5] END ...............pca__n_components=292;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=292;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=302;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=302;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=312;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=312;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=322;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=332;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=332;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=342;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=342;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=352;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=362;, score=nan total time=   0.4s\n",
      "[CV 2/5] END ...............pca__n_components=372;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=382;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=392;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=402;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=402;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=412;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=422;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=432;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=442;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=452;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=462;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=482;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=492;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=512;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=522;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=542;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=552;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=572;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=592;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=602;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=612;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=642;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=652;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=672;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=692;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=702;, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .............pca__n_components=2;, score=-66.836 total time=   9.9s\n",
      "[CV 2/5] END ............pca__n_components=22;, score=-28.641 total time=   9.5s\n",
      "[CV 4/5] END ............pca__n_components=32;, score=-24.957 total time=   9.4s\n",
      "[CV 2/5] END ............pca__n_components=52;, score=-18.079 total time=  11.1s\n",
      "[CV 5/5] END ............pca__n_components=62;, score=-22.045 total time=  11.5s\n",
      "[CV 3/5] END ............pca__n_components=82;, score=-19.743 total time=  14.1s\n",
      "[CV 1/5] END ...........pca__n_components=102;, score=-13.786 total time=  16.8s\n",
      "[CV 4/5] END ...........pca__n_components=112;, score=-16.341 total time=  16.7s\n",
      "[CV 2/5] END ...........pca__n_components=132;, score=-15.026 total time=  24.4s\n",
      "[CV 5/5] END ...........pca__n_components=142;, score=-18.561 total time=  22.2s\n",
      "[CV 3/5] END ...........pca__n_components=162;, score=-16.836 total time=  26.4s\n",
      "[CV 1/5] END ...........pca__n_components=182;, score=-13.029 total time=  25.8s\n",
      "[CV 4/5] END ...........pca__n_components=192;, score=-15.844 total time=  37.6s\n",
      "[CV 2/5] END ...........pca__n_components=212;, score=-14.886 total time=  16.8s\n",
      "[CV 1/5] END ...........pca__n_components=222;, score=-12.897 total time=  16.2s\n",
      "[CV 4/5] END ...........pca__n_components=232;, score=-15.470 total time=  15.6s\n",
      "[CV 2/5] END ...........pca__n_components=252;, score=-14.739 total time=  19.5s\n",
      "[CV 5/5] END ...........pca__n_components=262;, score=-17.852 total time=  13.3s\n",
      "[CV 4/5] END ...............pca__n_components=492;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=512;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=522;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=542;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=562;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=572;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=592;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=602;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=622;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=642;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=652;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=662;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=692;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=702;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ............pca__n_components=12;, score=-41.688 total time=  11.4s\n",
      "[CV 5/5] END ............pca__n_components=22;, score=-34.711 total time=  10.9s\n",
      "[CV 3/5] END ............pca__n_components=42;, score=-22.061 total time=  12.8s\n",
      "[CV 2/5] END ............pca__n_components=62;, score=-17.773 total time=  13.4s\n",
      "[CV 1/5] END ............pca__n_components=82;, score=-14.599 total time=  14.4s\n",
      "[CV 5/5] END ............pca__n_components=92;, score=-20.586 total time=  17.3s\n",
      "[CV 3/5] END ...........pca__n_components=112;, score=-17.788 total time=  15.5s\n",
      "[CV 4/5] END ...........pca__n_components=122;, score=-16.184 total time=  22.9s\n",
      "[CV 3/5] END ...........pca__n_components=142;, score=-17.143 total time=  22.6s\n",
      "[CV 5/5] END ...........pca__n_components=152;, score=-18.513 total time=  28.3s\n",
      "[CV 3/5] END ...........pca__n_components=172;, score=-16.812 total time=  25.1s\n",
      "[CV 1/5] END ...........pca__n_components=192;, score=-13.043 total time=  32.2s\n",
      "[CV 4/5] END ...........pca__n_components=202;, score=-15.675 total time=  37.2s\n",
      "[CV 5/5] END ...........pca__n_components=222;, score=-17.971 total time=  15.9s\n",
      "[CV 3/5] END ...........pca__n_components=242;, score=-16.354 total time=  18.3s\n",
      "[CV 1/5] END ...........pca__n_components=262;, score=-12.882 total time=  13.4s\n",
      "[CV 3/5] END ...............pca__n_components=352;, score=nan total time=   0.4s\n",
      "[CV 2/5] END ...............pca__n_components=362;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=372;, score=nan total time=   0.4s\n",
      "[CV 5/5] END ...............pca__n_components=372;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=382;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=392;, score=nan total time=   0.4s\n",
      "[CV 2/5] END ...............pca__n_components=402;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=412;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=412;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=422;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=432;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=442;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=462;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=472;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=482;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=502;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=532;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=542;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=562;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=572;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=582;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=612;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=632;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=632;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=642;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=672;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=682;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=692;, score=nan total time=   0.3s\n",
      "[CV 4/5] END .............pca__n_components=2;, score=-64.564 total time=   9.0s\n",
      "[CV 1/5] END ............pca__n_components=22;, score=-25.343 total time=  10.8s\n",
      "[CV 1/5] END ............pca__n_components=42;, score=-16.947 total time=   9.8s\n",
      "[CV 4/5] END ............pca__n_components=52;, score=-20.032 total time=  12.1s\n",
      "[CV 2/5] END ............pca__n_components=72;, score=-17.226 total time=  11.2s\n",
      "[CV 5/5] END ............pca__n_components=82;, score=-21.523 total time=  13.4s\n",
      "[CV 2/5] END ...........pca__n_components=102;, score=-15.992 total time=  18.4s\n",
      "[CV 5/5] END ...........pca__n_components=112;, score=-18.826 total time=  16.3s\n",
      "[CV 3/5] END ...........pca__n_components=132;, score=-17.172 total time=  24.5s\n",
      "[CV 1/5] END ...........pca__n_components=152;, score=-13.068 total time=  26.8s\n",
      "[CV 4/5] END ...........pca__n_components=162;, score=-16.013 total time=  26.6s\n",
      "[CV 2/5] END ...........pca__n_components=182;, score=-15.093 total time=  26.6s\n",
      "[CV 5/5] END ...........pca__n_components=192;, score=-18.428 total time=  36.8s\n",
      "[CV 3/5] END ...........pca__n_components=212;, score=-16.509 total time=  16.4s\n",
      "[CV 4/5] END ...........pca__n_components=222;, score=-15.557 total time=  14.1s\n",
      "[CV 2/5] END ...........pca__n_components=242;, score=-14.739 total time=  18.2s\n",
      "[CV 5/5] END ...........pca__n_components=252;, score=-17.833 total time=  16.9s\n",
      "[CV 4/5] END ...............pca__n_components=292;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=302;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=302;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=312;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=322;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=322;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=332;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=332;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=342;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=352;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=362;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=362;, score=nan total time=   0.4s\n",
      "[CV 4/5] END ...............pca__n_components=372;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=382;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=382;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=392;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=402;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=412;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=422;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=432;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=442;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=452;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=472;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=482;, score=nan total time=   0.2s\n",
      "[CV 3/5] END ...............pca__n_components=492;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=512;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=532;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=542;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=562;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=582;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=582;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=602;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=622;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=632;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=652;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=672;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=682;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=702;, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .............pca__n_components=2;, score=-72.516 total time=  10.0s\n",
      "[CV 3/5] END ............pca__n_components=22;, score=-32.091 total time=   9.4s\n",
      "[CV 5/5] END ............pca__n_components=32;, score=-27.231 total time=  10.1s\n",
      "[CV 3/5] END ............pca__n_components=52;, score=-21.005 total time=  10.5s\n",
      "[CV 1/5] END ............pca__n_components=72;, score=-15.121 total time=  12.0s\n",
      "[CV 4/5] END ............pca__n_components=82;, score=-18.357 total time=  14.6s\n",
      "[CV 3/5] END ...........pca__n_components=102;, score=-18.405 total time=  18.7s\n",
      "[CV 1/5] END ...........pca__n_components=122;, score=-13.075 total time=  17.9s\n",
      "[CV 4/5] END ...........pca__n_components=132;, score=-16.135 total time=  23.6s\n",
      "[CV 2/5] END ...........pca__n_components=152;, score=-15.176 total time=  28.4s\n",
      "[CV 5/5] END ...........pca__n_components=162;, score=-18.375 total time=  27.3s\n",
      "[CV 3/5] END ...........pca__n_components=182;, score=-16.748 total time=  28.0s\n",
      "[CV 1/5] END ...........pca__n_components=202;, score=-12.983 total time=  37.3s\n",
      "[CV 4/5] END ...........pca__n_components=212;, score=-15.616 total time=  18.5s\n",
      "[CV 2/5] END ...........pca__n_components=232;, score=-14.752 total time=  17.1s\n",
      "[CV 1/5] END ...........pca__n_components=252;, score=-12.828 total time=  18.1s\n",
      "[CV 4/5] END ...........pca__n_components=262;, score=-15.478 total time=  13.8s\n",
      "[CV 5/5] END ...............pca__n_components=432;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=452;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=462;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=472;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=492;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=502;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=532;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=532;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=552;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=572;, score=nan total time=   0.3s\n",
      "[CV 1/5] END ...............pca__n_components=592;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=602;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=622;, score=nan total time=   0.3s\n",
      "[CV 4/5] END ...............pca__n_components=632;, score=nan total time=   0.3s\n",
      "[CV 3/5] END ...............pca__n_components=652;, score=nan total time=   0.3s\n",
      "[CV 5/5] END ...............pca__n_components=672;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=682;, score=nan total time=   0.3s\n",
      "[CV 2/5] END ...............pca__n_components=702;, score=nan total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "# set the tolerance to a large value to make the example faster\n",
    "regressor = LinearRegression()\n",
    "pipe = Pipeline(steps=[(\"pca\", pca), (\"regressor\", regressor)])\n",
    "\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    \"pca__n_components\": np.arange(2,705,10),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid,n_jobs=-1,scoring='neg_mean_absolute_error',verbose=3)\n",
    "search.fit(x_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "8c58c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778222058876295\n",
      "16.706370517917016\n",
      "32.59769746538075\n",
      "0.0006799861722539143\n",
      "0.49722418116913797\n"
     ]
    }
   ],
   "source": [
    "y_pred = search.best_estimator_.predict(x_test)\n",
    "print(r2_score(y_pred,y_test))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False))\n",
    "print(mean_squared_error(y_test,y_pred,squared=False)/np.mean(np.var(y_pred)))\n",
    "print(masked_MAPE(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b72e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(VNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Linear(input_size, n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,n_feature),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(n_feature,output_size),\n",
    "        )\n",
    " \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.layer1(x)        \n",
    "        return x\n",
    "\n",
    "def get_loss_and_metrics(model, batch, criterion, device):\n",
    "  # Implement forward pass and loss calculation for one batch.\n",
    "  # Remember to move the batch to device.\n",
    "  # \n",
    "  # Return a tuple:\n",
    "  # - loss for the batch (Tensor)\n",
    "  # - number of correctly classified examples in the batch (Tensor)\n",
    "    data, target = batch[0], batch[1]\n",
    "    data = torch.tensor(data, dtype=torch.float32)\n",
    "    target = torch.tensor(target, dtype=torch.float32)\n",
    "    \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(data)\n",
    "    loss = criterion(pred, target)\n",
    "    \n",
    "    \n",
    "    return (pred,target,loss)\n",
    "    \n",
    "def step(loss, optimizer):\n",
    "  # Implement backward pass and update.\n",
    "\n",
    "  # TODO\n",
    "    loss = loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "026ed6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = od.iloc[:-24*50*7,5:].values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(fts)\n",
    "fts = torch.tensor(scaler.transform(fts))\n",
    "target = torch.tensor(od.iloc[:-24*50*7,3:5].values)                      \n",
    "train_dataset = torch.utils.data.TensorDataset(fts,target)\n",
    "                      \n",
    "fts_val = torch.tensor(scaler.transform(od.iloc[-24*50*7:,5:].values))                   \n",
    "target_val = torch.tensor(od.iloc[-24*50*7:,3:5].values)                      \n",
    "validation_dataset = torch.utils.data.TensorDataset(fts_val, target_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b34f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "N_EPOCHS = 5000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=len(validation_dataset),\n",
    "                                                    num_workers=0)\n",
    "model = VNN(input_size=od.shape[1]-5,n_feature=64,output_size=2)\n",
    "model = model.to(device)\n",
    "criterion = nn.SmoothL1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07735b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss:104.2552 validation_mae:111.2601 validation R2: -110161888655.0063:   0%|                     | 0/5000 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m---> 19\u001b[0m     y_pred,y_true,loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_loss_and_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     step(loss\u001b[38;5;241m.\u001b[39mfloat(), optimizer)\n\u001b[1;32m     21\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_loss_and_metrics\u001b[0;34m(model, batch, criterion, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     31\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(target, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 33\u001b[0m data, target \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) \n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "pbar = tqdm(range(N_EPOCHS))\n",
    "\n",
    "validation_mae = 99999999\n",
    "mean_train_loss = 999999\n",
    "for i in pbar: \n",
    "    while validation_mae > 10 and mean_train_loss > 1:\n",
    "        total_train_loss = 0.0\n",
    "        total_train_mae = 0.0\n",
    "        total_train_r2 = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            y_pred,y_true,loss = get_loss_and_metrics(model, batch, criterion, device)\n",
    "            step(loss.float(), optimizer)\n",
    "            total_train_loss += loss.item()\n",
    "#             size = y_pred.shape[0]\n",
    "#             mae = mean_absolute_error(y_pred.detach().cpu().numpy(),y_true.detach().cpu().numpy())\n",
    "#             r2 = r2_score(y_pred.view(size,2).detach().cpu().numpy(),y_true.view(size,2).detach().cpu().numpy())\n",
    "#             total_train_mae += mae\n",
    "#             total_train_r2 += r2\n",
    "        for batch in validation_dataloader:\n",
    "            with torch.no_grad(): \n",
    "#                 print(batch[0].shape)\n",
    "                y_pred,y_true,loss = get_loss_and_metrics(model, batch, criterion, device)\n",
    "#                 print(y_pred.shape)\n",
    "                total_validation_loss = loss.item()\n",
    "                size = y_pred.shape[0]\n",
    "                validation_mae = mean_absolute_error(y_pred.view(size,2).detach().cpu().numpy()\n",
    "                                                     ,y_true.view(size,2).detach().cpu().numpy())\n",
    "                validation_r2 = r2_score(y_pred.view(size,2).detach().cpu().numpy(),y_true.view(size,2).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        mean_train_loss = total_train_loss / len(train_dataloader)\n",
    "        train_mae = total_train_mae / len(train_dataloader)\n",
    "        train_r2 = total_train_r2 / len(train_dataloader)\n",
    "\n",
    "        mean_validation_loss = total_validation_loss / len(validation_dataloader)\n",
    "\n",
    "        pbar.set_description('train_loss:'+ str(round(mean_train_loss,4))+ \\\n",
    "                             ' validation_mae:'+ str(round(validation_mae,4)) +\\\n",
    "                            ' validation R2: '+ str(round(validation_r2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "ce0cc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in validation_dataloader:\n",
    "    with torch.no_grad(): \n",
    "        y_pred,y_true,loss = get_loss_and_metrics(model, batch, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "788b0caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33., 11.],\n",
       "       [35., 33.],\n",
       "       [57.,  4.],\n",
       "       ...,\n",
       "       [22., 16.],\n",
       "       [ 7.,  5.],\n",
       "       [71., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "66af217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097482689371424\n",
      "21.502193\n",
      "66.24005\n",
      "0.30688763313285594\n"
     ]
    }
   ],
   "source": [
    "y_true,y_pred = y_true.cpu().numpy(),y_pred.cpu().numpy()\n",
    "print(r2_score(y_true,y_pred))\n",
    "print(mean_absolute_error(y_true,y_pred))\n",
    "print(mean_squared_error(y_true,y_pred,squared=False))\n",
    "print(masked_MAPE(y_true,y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
